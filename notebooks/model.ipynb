{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv('../data/clean/tanzania.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Lat and Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df.drop(['target', 'latitude', 'longitude', 'population'], axis=1)\n",
    "y = clean_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = list(X.select_dtypes(include=np.number).columns)\n",
    "categorical_cols = list(X.select_dtypes(exclude=np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('scale', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "- LinearSVC\n",
    "- k-NN\n",
    "- Support Vector Machine Algorithm\n",
    "- XGBoost\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict\n",
    "TODO: add SMOTE option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fit_predict(model, X_train, X_test, y_train, y_test):\n",
    "    '''fit pipeline using given model, and return predictions'''\n",
    "    \n",
    "    param_grid = model['params']\n",
    "    model = model['model']\n",
    "        \n",
    "    # Bundle preprocessing and modeling code in a pipeline\n",
    "    my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', model)\n",
    "                                 ])\n",
    "    \n",
    "    search = GridSearchCV(estimator=my_pipeline,\n",
    "             param_grid=param_grid, n_jobs=-1)\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "    print(search.best_params_)\n",
    "\n",
    "    # Preprocessing of validation data, get predictions\n",
    "    test_preds = search.predict(X_test)\n",
    "    train_preds = search.predict(X_train)\n",
    "    return test_preds, train_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "What are the most important things to look for with regression?\n",
    "\n",
    "TODO: add graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def metrics(model_name, y_train, y_test, y_train_pred, y_test_pred):\n",
    "    '''Print out the evaluation metrics for a given models predictions'''\n",
    "    print(f'Model: {model_name}', )\n",
    "    print('-'*60)\n",
    "    print(f'test accuracy: {accuracy_score(y_test, y_test_pred)}')\n",
    "    print(f'train accuracy: {accuracy_score(y_train, y_train_pred)}')\n",
    "    print('-'*60)\n",
    "    print('\\ntest report:\\n' + classification_report(y_test, y_test_pred))\n",
    "    print('~'*60)\n",
    "    print('\\ntrain report:\\n' + classification_report(y_train, y_train_pred))    \n",
    "    print('-'*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why LinearSVC\n",
    "The objective of a Linear SVC (Support Vector Classifier) is to fit to the data you provide, returning a \"best fit\"\n",
    "hyperplane that divides, or categorizes, your data. \n",
    "\n",
    "It has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "LinearSVC is another (faster) implementation of Support Vector Classification for the case of a linear kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    # \n",
    "    'model__C': [0.1,1, 10, 100], \n",
    "    'model__tol': [1,0.1,0.01,0.001],\n",
    "    'model__max_iter': [10000],\n",
    "    'model__penalty': ['l1', 'l2'],\n",
    "    'model__multi_class': ['ovr', 'crammer_singer']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=42)\n",
    "\n",
    "lsvc = { 'model': LinearSVC(), 'params': param_dict }\n",
    "\n",
    "test_preds, train_preds = fit_predict(lsvc, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics('LinearSVC', y_train, y_test, train_preds, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a debate that LinearSVC is not a good fit for multi-class classification problems.\n",
    "\n",
    "There are some ways to adjust for it: \n",
    "- using the 'crammer_singer' algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why KNN\n",
    "KNNs are a non-parametric, lazy learning algorithm. It makes no underlying assumptions about the distribution of data. \n",
    "\n",
    "No training is necessary! \n",
    "\n",
    "KNN makes predictions just-in-time by calculating the similarity between an input sample and each training instance.\n",
    "\n",
    "It is a Simple algorithm — to explain and understand/interpret. It is versatile — useful for classification or regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    # amount of neighbors\n",
    "    'model__n_neighbors': range(1, 10, 2),\n",
    "    # leaf size\n",
    "    'model__leaf_size': range(30, ),\n",
    "    'model__weights': ['uniform', 'distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = { 'model': KNeighborsClassifier(), 'params': param_dict }\n",
    "\n",
    "test_preds, train_preds = fit_predict(knn, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics('k-NN', y_train, y_test, train_preds, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpd]",
   "language": "python",
   "name": "conda-env-gpd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
